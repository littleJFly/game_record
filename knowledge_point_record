#### 知识点记录  #####

ps -ef | grep java  -- 查看进程信息

kill -9 xxx  -- 杀进程 xxx

killall telnet   -- 怕不小心删错进程,导致位置错误,,安全的杀死进程方法:

jmap -heap <pid>　　打印堆的使用情况

jmap -histo[:live] <pid>　　打印类的实例数量、占用的内存、类的名称，通常我们并不需要看所有的，只需要看前几条即可

jmap -dump:live,format=b,file=heap.bin <pid>　　
以hprof二进制格式dump堆的使用情况（PS：相当于生成一个快照，后续我们可以对这个快照文件进行分析）

jstack [pid] ,线程的所有堆栈信息 可以查看线程执行状态，是否死锁

jstat -gcutil pid interval(ms) : 查看jvm gc垃圾回收情况 (间隔时间不加的话默认直接打印一条)


分布式锁实现
分布式 CAP 理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance），最多只能同时满足两项。”，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。在很多场景中为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。有的时候需要保证一个方法在同一时间内只能被同一个线程执行。 分布式锁一般有三种实现方式：

基于数据库实现分布式锁；
基于缓存（Redis，Memcached，Tair）实现分布式锁；
基于 ZooKeeper 实现分布式锁；
基于数据库实现分布式锁
基于数据库实现分布式锁的核心思想：在数据库中创建一张表，表里包含方法名等字段，并且在方法名字段上面创建唯一索引，执行某个方法需要使用此方法名向表中插入数据，成功插入则获取锁，执行结束则删除对应的行数据释放锁。

基于缓存实现分布式锁
基于缓存通常选用 Redis 实现分布式锁，考虑到 Redis 有非常高的性能，Redis 命令对分布式锁支持友好，并且实现方便。基于单 Redis 节点的分布式锁在 Failover 的时候产生解决不了的安全性问题，Redlock 是 Redis 的作者 Antirez 提出的集群模式 Redis 分布式锁，基于 N 个完全独立的 Redis 节点（通常情况下 N 可以设置成5），运行 Redlock 算法依次执行下面各个步骤完成获取锁的操作

获取当前时间（毫秒数）；
按顺序依次向 N 个 Redis 节点执行获取锁的操作。此获取操作包含随机字符串 my_random_value，也包含过期时间(比如 PX 30000，即锁的有效时间)。为了保证在某个 Redis 节点不可用的时候算法能够继续运行，获取锁的操作还有超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个 Redis 节点获取锁失败以后应该立即尝试下一个Redis 节点。这里的失败包含任何类型的失败，比如该 Redis 节点不可用，或者该 Redis 节点上的锁已经被其它客户端持有（注：Redlock 原文中这里只提及 Redis 节点不可用的情况，但也应该包含其它的失败情况）；
计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数 Redis 节点（>= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间（lock validity time），那么这时客户端才认为最终获取锁成功；否则认为最终获取锁失败；

博客链接
https://www.sofastack.tech/blog/sofa-jraft-rheakv-distributedlock/

https://www.sofastack.tech/blog/sofa-jraft-rheakv-distributedlock/
如果最终获取锁成功了，那么此锁的有效时间应该重新计算，它等于最初锁的有效时间减去第3步计算出来的获取锁消耗的时间；
如果最终获取锁失败（可能由于获取到锁的 Redis 节点个数少于 N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端立即向所有 Redis 节点发起释放锁的操作；
基于 ZooKeeper 实现分布式锁
ZooKeeper 是以 Paxos 算法为基础的分布式应用程序协调服务，为分布式应用提供一致性服务的开源组件，其内部是分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名。基于 ZooKeeper 实现分布式锁步骤包括：

创建一个锁目录 lock；
希望获得锁的线程 A 在 lock 目录下创建临时顺序节点；
当前线程获取锁目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在表示当前线程顺序号最小，获得锁；
线程 B 获取所有节点，判断自己不是最小节点，设置监听（Watcher）比自己次小的节点（只关注比自己次小的节点是为了防止发生“羊群效应”）；
线程 A 处理完删除自己的节点，线程 B 监听到变更事件判断自己是否为最小的节点，如果是则获得锁；
RheaKV 分布式锁实现
RheaKV 是基于 SOFAJRaft 和 RocksDB 实现的嵌入式、分布式、高可用、强一致的 KV 存储类库，RheaKV 提供 DistributedLock 实现可重入锁，自动续租以及 Fencing Token 功能特性。DistributedLock 是可重入锁， tryLock() 与 unlock() 必须成对出现。RheaKV 调用 getDistributedLock 接口获取分布式锁实例，其中参数：

 target 理解为分布式锁的 key, 不同锁的 key 不能重复，但是锁的存储空间是与其他 KV 数据隔离的，所以只需保证 key 在 ‘锁空间’ 内的唯一性即可；
lease 必须包含锁的租约（lease）时间，在锁到期之前如果 watchdog 为空那么锁会被自动释放，即没有 watchdog 配合的 lease 就是 timeout 的意思；
watchdog 表示自动续租的调度器，需要用户自行创建并销毁，框架内部不负责该调度器的生命周期管理，如果 watchdog 不为空定期（lease 的 2⁄3 时间为周期）主动为当前的锁不断进行续租，直到用户主动释放锁（unlock）；
